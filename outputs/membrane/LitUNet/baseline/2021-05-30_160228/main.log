[2021-05-30 16:02:28,604][lightning][INFO] - Global seed set to 1234
[2021-05-30 16:02:28,607][__main__][INFO] - 
data:
  name: membrane
  _target_: project.dataset.LitUNetDataModule
  data_dir: /home/carter.fang/git/pytorch-unet/data/membrane/train
  val_ratio: 0.1
  batch_size: 1
  num_workers: 8
  input_channels: 1
  n_classes: 1
model:
  optimizer:
    _target_: torch.optim.SGD
    lr: 0.001
    momentum: 0.99
  name: LitUNet
  _target_: project.litmodel.LitUNet
  input_channels: 1
  n_prefeats: 64
  n_classes: 1
experiment: baseline
trainer:
  benchmark: true
  gpus: 1
  terminate_on_nan: true

[2021-05-30 16:02:28,949][lightning][INFO] - GPU available: True, used: True
[2021-05-30 16:02:28,950][lightning][INFO] - TPU available: None, using: 0 TPU cores
[2021-05-30 16:02:28,951][pytorch_lightning.accelerators.gpu][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[2021-05-30 16:02:31,255][lightning][INFO] - 
  | Name        | Type              | Params
--------------------------------------------------
0 | pre_encoder | SequentialConv    | 37.8 K
1 | pre_down    | MaxPool2d         | 0     
2 | encoder     | Encoder           | 4.7 M 
3 | bottleneck  | SequentialConv    | 14.2 M
4 | decoder     | Decoder           | 12.2 M
5 | output_conv | Conv2d            | 65    
6 | train_f1    | DiceCoefficient   | 0     
7 | val_f1      | DiceCoefficient   | 0     
8 | loss_fn     | BCEWithLogitsLoss | 0     
9 | output_fn   | Sigmoid           | 0     
--------------------------------------------------
31.0 M    Trainable params
0         Non-trainable params
31.0 M    Total params
124.169   Total estimated model params size (MB)
